Thanks! Based on your code, here is a complete and professional `README.md` you can use for your GitHub repo:

* * * * *

```

# ğŸ¤– AI Interviewer (LangGraph-based)

AI Interviewer is a multi-agent interview simulation system powered by **LangGraph** and **LLMs (OpenAI or local models)**. It conducts technical interviews by:

- Asking topic-based theoretical questions

- Evaluating answers using a scoring rubric

- Summarizing the candidate's performance

---

## ğŸ“¦ Features

- âœ… Multi-agent LangGraph: Question â†’ Evaluation â†’ Performance

- âœ… OpenAI or Local LLMs (e.g., via Groq, Ollama, etc.)

- âœ… CLI interface for live interview simulation

- âœ… Auto-scoring of answers based on technical depth, clarity, terminology, etc.

- âœ… Final score and performance summary after 5 rounds

- âœ… Optional Tavily search tool for grounded question generation

---

## ğŸ› ï¸ Technologies Used

- [LangGraph](https://docs.langgraph.dev/)

- [LangChain](https://www.langchain.com/)

- [OpenAI API](https://platform.openai.com/) or [Groq API](https://console.groq.com/)

- [Tavily Search API](https://www.tavily.com/) *(optional)*

- [Pydantic](https://docs.pydantic.dev/) (for structured response validation)

- Python 3.10+

---

## ğŸ“ Project Structure

```

.

â”œâ”€â”€ main.py # CLI runner

â”œâ”€â”€ graph.py # LangGraph setup with agents + supervisor

â”œâ”€â”€ llm.py # LLM config (OpenAI or local)

â”œâ”€â”€ tools.py # External tools like Tavily

â”œâ”€â”€ schema.py # Pydantic response schemas

â”œâ”€â”€ prompts.py # All custom agent prompts

â””â”€â”€ .env # API keys

```

---

## ğŸ§  System Flow & Design

1\. **Supervisor Agent** orchestrates the interview session.

2\. **Question Agent** generates a theoretical question based on the given topic.

3\. User answers the question via CLI.

4\. **Evaluation Agent** scores the answer on a 10-point rubric and summarizes it.

5\. After 5 rounds, the **Performance Agent**:

Â  Â - Calculates a total score out of 100

Â  Â - Generates a concise technical performance summary (max 250 chars)

### ğŸ§­ Branching Logic

- If score < 6 â†’ Supervisor can ask simpler follow-up questions (optional future enhancement)

- If user enters "FINAL_EVAL" â†’ Shortcut to trigger performance summary

- Evaluation results are stored in internal state (only final summary is shown)

---

## ğŸš€ Setup Instructions

### 1. Clone the repo

```bash

git clone https://github.com/your-username/ai-interviewer.git

cd ai-interviewer

```

### 2\. Install dependencies

```

pip install -r requirements.txt

```

> If you use local LLMs (e.g., Groq or Ollama), include the corresponding LangChain packages.

### 3\. Add API keys to `.env`

```

OPEN_AI_KEY=your_openai_key_here

GROQ_API_KEY=your_groq_key_here

TAVILY_API_KEY=your_tavily_key_hereÂ  # Optional

```

### 4\. Run the CLI

```

python main.py

```

ğŸ”§ Optional Features Implemented

--------------------------------

-Â  Â âœ… Dynamic prompt templates for each agent

-Â  Â âœ… LangGraph memory using `InMemoryStore` and `InMemorySaver`

-Â  Â âœ… Structured schema validation via Pydantic

-Â  Â âœ… Configurable LLM backend (`ChatOpenAI` / `ChatGroq`)

-Â  Â âœ… Plug-and-play external tools (e.g., Tavily)

ğŸ“„ License

----------

MIT License --- free to use and modify.

* * * * *

ğŸ™Œ Acknowledgements

-------------------

Built using:

-Â  Â [LangGraph](https://github.com/langchain-ai/langgraph)

-Â  Â [OpenAI](https://platform.openai.com/)

-Â  Â [LangChain](https://www.langchain.com/)

-Â  Â [Tavily](https://www.tavily.com/)

```

---

```
